>>> from pandas import Series,DataFrame
>>> import numpy as np
>>> import pandas as pd
>>> df1=DataFrame({'key':['b','b','a','c','a','a','b'],'data1':range(7)})
>>> df2=DataFrame({'key':['a','b','d'],'data2':range(3)})
>>> df1
  key  data1
0   b      0
1   b      1
2   a      2
3   c      3
4   a      4
5   a      5
6   b      6
>>> df2
  key  data2
0   a      0
1   b      1
2   d      2
>>> pd.merge(df1,df2)
  key  data1  data2
0   b      0      1
1   b      1      1
2   b      6      1
3   a      2      0
4   a      4      0
5   a      5      0
>>> #merge将重叠列的列名当做键
>>> pd.merge(df1,df2,on='key')
  key  data1  data2
0   b      0      1
1   b      1      1
2   b      6      1
3   a      2      0
4   a      4      0
5   a      5      0
>>> df3=DataFrame({'lkey':['b','b','a','c','a','a','b'],'data1':range(7)})
>>> df4=DataFrame({'rkey':['a','b','d'],'data2':range(3)})
>>> pd.merge(df3,df4,left_on='lkey',right_on='rkey')
  lkey  data1 rkey  data2
0    b      0    b      1
1    b      1    b      1
2    b      6    b      1
3    a      2    a      0
4    a      4    a      0
5    a      5    a      0
>>> pd.merge(df1,df2,how='outer')
  key  data1  data2
0   b    0.0    1.0
1   b    1.0    1.0
2   b    6.0    1.0
3   a    2.0    0.0
4   a    4.0    0.0
5   a    5.0    0.0
6   c    3.0    NaN
7   d    NaN    2.0
>>> df1=DataFrame({'key':['b','b','a','c','a','b'],'data1':range(6)})
>>> df2=DataFrame({'key':['a','b','a','b','d'],'data2':range(5)})
>>> df1
  key  data1
0   b      0
1   b      1
2   a      2
3   c      3
4   a      4
5   b      5
>>> df2
  key  data2
0   a      0
1   b      1
2   a      2
3   b      3
4   d      4
>>> pd.merge(df1,df2,on='key',how='left')
   key  data1  data2
0    b      0    1.0
1    b      0    3.0
2    b      1    1.0
3    b      1    3.0
4    a      2    0.0
5    a      2    2.0
6    c      3    NaN
7    a      4    0.0
8    a      4    2.0
9    b      5    1.0
10   b      5    3.0
>>> pd.merge(df1,df2,how='inner')
  key  data1  data2
0   b      0      1
1   b      0      3
2   b      1      1
3   b      1      3
4   b      5      1
5   b      5      3
6   a      2      0
7   a      2      2
8   a      4      0
9   a      4      2
>>> left=DataFrame({'key1':['foo','foo','bar'],
		    'key2':['one','two','one'],
		    'lval':[1,2,3]})
>>> right=DataFrame({'key1':['foo','foo','bar','bar'],
		     'key2':['one','one','one','two'],
		     'rval':[4,5,6,7]})
>>> pd.merge(left,right,on=['key1','key2'],how='outer')
  key1 key2  lval  rval
0  foo  one   1.0   4.0
1  foo  one   1.0   5.0
2  foo  two   2.0   NaN
3  bar  one   3.0   6.0
4  bar  two   NaN   7.0
>>> pd.merge(left,right,on='key1')
  key1 key2_x  lval key2_y  rval
0  foo    one     1    one     4
1  foo    one     1    one     5
2  foo    two     2    one     4
3  foo    two     2    one     5
4  bar    one     3    one     6
5  bar    one     3    two     7
>>> pd.merge(left,right,on='key1',suffixes=('_left','_right'))
  key1 key2_left  lval key2_right  rval
0  foo       one     1        one     4
1  foo       one     1        one     5
2  foo       two     2        one     4
3  foo       two     2        one     5
4  bar       one     3        one     6
5  bar       one     3        two     7
>>> #参数          说明
>>> #left    参与合并的左侧DataFrame
>>> #right   参与合并的右侧DataFrame
>>> #how     "inner" "outer" "left" "right"其中之一，默认为"inner"
>>> left1=DataFrame({'key':['a','b','a','a','b','c'],
		     'value':range(6)})
>>> right1=DataFrame({'group_val':[3.5,7]},index=['a','b'])
>>> left1
  key  value
0   a      0
1   b      1
2   a      2
3   a      3
4   b      4
5   c      5
>>> right1
   group_val
a        3.5
b        7.0
>>> pd.merge(left1,right1,left_on='key',right_index=True)
  key  value  group_val
0   a      0        3.5
2   a      2        3.5
3   a      3        3.5
1   b      1        7.0
4   b      4        7.0
>>> pd.merge(left1,right1,left_on='key',right_index=True,how='outer')
  key  value  group_val
0   a      0        3.5
2   a      2        3.5
3   a      3        3.5
1   b      1        7.0
4   b      4        7.0
5   c      5        NaN
>>> lefth=DataFrame({'key1':['Ohio','Ohio','Ohio','Nevada','Nevada'],
		     'key2':[2000,2001,2002,2001,2002],
		     'data':np.arange(5,)})
>>> righth=DataFrame(np.arange(12).reshape((6,2)),
		     index=[['Nevada','Nevada','Ohio','Ohio','Ohio','Ohio'],
			    [2001,2000,2000,2000,2001,2002]],
		     columns=['event1','event2'])
>>> lefth
     key1  key2  data
0    Ohio  2000     0
1    Ohio  2001     1
2    Ohio  2002     2
3  Nevada  2001     3
4  Nevada  2002     4
>>> righth
             event1  event2
Nevada 2001       0       1
       2000       2       3
Ohio   2000       4       5
       2000       6       7
       2001       8       9
       2002      10      11
>>> pd.merge(lefth,righth,left_on=['key1','key2'],right_index=True)
     key1  key2  data  event1  event2
0    Ohio  2000     0       4       5
0    Ohio  2000     0       6       7
1    Ohio  2001     1       8       9
2    Ohio  2002     2      10      11
3  Nevada  2001     3       0       1
>>> pd.merge(lefth,righth,left_on=['key1','key2'],
	     right_index=True,how='outer')
     key1  key2  data  event1  event2
0    Ohio  2000   0.0     4.0     5.0
0    Ohio  2000   0.0     6.0     7.0
1    Ohio  2001   1.0     8.0     9.0
2    Ohio  2002   2.0    10.0    11.0
3  Nevada  2001   3.0     0.0     1.0
4  Nevada  2002   4.0     NaN     NaN
4  Nevada  2000   NaN     2.0     3.0
>>> left2=DataFrame([[1.,2.],[3.,4.],[5.,6.]],index=['a','c','e'],
		    columns=['Ohio','Nevada'])
>>> right2=DataFrame([[7.,8.],[9.,10.],[11.,12.],[13,14]],
		     index=['b','c','d','e'],columns=['Missouri','Alabama'])
>>> left2
   Ohio  Nevada
a   1.0     2.0
c   3.0     4.0
e   5.0     6.0
>>> right2
   Missouri  Alabama
b       7.0      8.0
c       9.0     10.0
d      11.0     12.0
e      13.0     14.0
>>> pd.merge(left2,right2,how='outer',left_index=True,right_index=True)
   Ohio  Nevada  Missouri  Alabama
a   1.0     2.0       NaN      NaN
b   NaN     NaN       7.0      8.0
c   3.0     4.0       9.0     10.0
d   NaN     NaN      11.0     12.0
e   5.0     6.0      13.0     14.0
>>> left2.join(right2,how='outer')
   Ohio  Nevada  Missouri  Alabama
a   1.0     2.0       NaN      NaN
b   NaN     NaN       7.0      8.0
c   3.0     4.0       9.0     10.0
d   NaN     NaN      11.0     12.0
e   5.0     6.0      13.0     14.0
>>> #join可以更方便地实现按索引合并。
>>> left1.join(right1,on='key')
  key  value  group_val
0   a      0        3.5
1   b      1        7.0
2   a      2        3.5
3   a      3        3.5
4   b      4        7.0
5   c      5        NaN
>>> another=DataFrame([[7.,8.],[9.,10.],[11.,12.],[16.,17.]],
		      index=['a','c','e','f'],columns=['New York','Oregon'])
>>> left2.join([right2,another])
   Ohio  Nevada  Missouri  Alabama  New York  Oregon
a   1.0     2.0       NaN      NaN       7.0     8.0
c   3.0     4.0       9.0     10.0       9.0    10.0
e   5.0     6.0      13.0     14.0      11.0    12.0
>>> right2.join([another])
   Missouri  Alabama  New York  Oregon
b       7.0      8.0       NaN     NaN
c       9.0     10.0       9.0    10.0
d      11.0     12.0       NaN     NaN
e      13.0     14.0      11.0    12.0
>>> left2.join([right2,another],how='outer')

Warning (from warnings module):
  File "D:\python\python3.6.6\lib\site-packages\pandas\core\frame.py", line 6848
    verify_integrity=True)
FutureWarning: Sorting because non-concatenation axis is not aligned. A future version
of pandas will change to not sort by default.

To accept the future behavior, pass 'sort=False'.

To retain the current behavior and silence the warning, pass 'sort=True'.

   Ohio  Nevada  Missouri  Alabama  New York  Oregon
a   1.0     2.0       NaN      NaN       7.0     8.0
b   NaN     NaN       7.0      8.0       NaN     NaN
c   3.0     4.0       9.0     10.0       9.0    10.0
d   NaN     NaN      11.0     12.0       NaN     NaN
e   5.0     6.0      13.0     14.0      11.0    12.0
f   NaN     NaN       NaN      NaN      16.0    17.0
>>> arr=np.arange(12).reshape((3,4))
>>> arr
array([[ 0,  1,  2,  3],
       [ 4,  5,  6,  7],
       [ 8,  9, 10, 11]])
>>> #concatenation连接
>>> np.concatenate([arr,arr],axis=1)
array([[ 0,  1,  2,  3,  0,  1,  2,  3],
       [ 4,  5,  6,  7,  4,  5,  6,  7],
       [ 8,  9, 10, 11,  8,  9, 10, 11]])
>>> s1=Series([0,1],index=['a','b'])
>>> s2=Series([2,3,4],index=['c','d','e'])
>>> s3=Series([5,6],index=['f','g'])
>>> pd.concat([s1,s2,s3])
a    0
b    1
c    2
d    3
e    4
f    5
g    6
dtype: int64
>>> #对这些对象调用concat可以将值和索引黏在一起
>>> #默认情况下，concat是在axis=1上工作的，最终产生一个新的Series。如果传入axis=1,则结果就会变成一个DataFrame(axis是列)
>>> pd.concat([s1,s2,s3],axis=1)

Warning (from warnings module):
  File "__main__", line 1
FutureWarning: Sorting because non-concatenation axis is not aligned. A future version
of pandas will change to not sort by default.

To accept the future behavior, pass 'sort=False'.

To retain the current behavior and silence the warning, pass 'sort=True'.

     0    1    2
a  0.0  NaN  NaN
b  1.0  NaN  NaN
c  NaN  2.0  NaN
d  NaN  3.0  NaN
e  NaN  4.0  NaN
f  NaN  NaN  5.0
g  NaN  NaN  6.0
>>> s4=pd.concat([s1*5,s3])
>>> pd.concat([s1,s4],axis=1)
     0  1
a  0.0  0
b  1.0  5
f  NaN  5
g  NaN  6
>>> pd.concat([s1,s4],axis=1,join='inner')
   0  1
a  0  0
b  1  5
>>> pd.concat([s1,s4],axis=1,join_axes=[['a','c','b','e']])
     0    1
a  0.0  0.0
c  NaN  NaN
b  1.0  5.0
e  NaN  NaN
>>> result=pd.concat([s1,s1,s3],keys=['one','two','three'])
>>> result
one    a    0
       b    1
two    a    0
       b    1
three  f    5
       g    6
dtype: int64
>>> #假如想在连接轴上创建一个层次化索引，使用keys参数即可达到这个目的
>>> result.unstack()
         a    b    f    g
one    0.0  1.0  NaN  NaN
two    0.0  1.0  NaN  NaN
three  NaN  NaN  5.0  6.0
>>> pd.concat([s1,s2,s3],axis=1,keys=['one','two','three'])
   one  two  three
a  0.0  NaN    NaN
b  1.0  NaN    NaN
c  NaN  2.0    NaN
d  NaN  3.0    NaN
e  NaN  4.0    NaN
f  NaN  NaN    5.0
g  NaN  NaN    6.0
>>> #如果沿着axis=1对Series进行合并，则keys就会成为DataFrame的列头
>>> df1=DataFrame(np.arange(6).reshape(3,2),index=['a','b','c'],columns=['one','two'])
>>> df2=DataFrame(5+np.arange(4).reshape(2,2),index=['a','c'],columns=['three','four'])
>>> pd.concat([df1,df2],axis=1,keys=['level1','level2'])
  level1     level2     
     one two  three four
a      0   1    5.0  6.0
b      2   3    NaN  NaN
c      4   5    7.0  8.0
>>> pd.concat({'level1':df1,'level2':df2},axis=1)
  level1     level2     
     one two  three four
a      0   1    5.0  6.0
b      2   3    NaN  NaN
c      4   5    7.0  8.0
>>> pd.concat([df1,df2],axis=1,keys=['level1','level2'],names=['upper','lower'])
upper level1     level2     
lower    one two  three four
a          0   1    5.0  6.0
b          2   3    NaN  NaN
c          4   5    7.0  8.0
>>> df1=DataFrame(np.random.randn(3,4),columns=['a','b','c','d'])
>>> df2=DataFrame(np.random.randn(2,3),columns=['b','d','a'])
>>> df1
          a         b         c         d
0  0.710214 -0.470484 -1.208146  0.203787
1  1.049561 -0.891504 -1.154794  1.155787
2  0.471315 -1.804562 -0.112889  0.223417
>>> df2
          b         d         a
0 -1.890895 -0.659234 -0.339777
1 -0.115062 -0.515415  1.815228
>>> pd.concat([df1,df2],ignore_index=True)
          a         b         c         d
0  0.710214 -0.470484 -1.208146  0.203787
1  1.049561 -0.891504 -1.154794  1.155787
2  0.471315 -1.804562 -0.112889  0.223417
3 -0.339777 -1.890895       NaN -0.659234
4  1.815228 -0.115062       NaN -0.515415
>>> #ignore_index：不保留连接轴上的索引，产生一组新索引range(total_
>>> a=Series([np.nan,2.5,np.nan,3.5,4.5,np.nan],
	     index=['f','e','d','c','b','a'])
>>> b=Series(np.arange(len(a),dtype=np.float64),index=['f','e','d','c','b','a'])
>>> b[-1]=np.nan
>>> a
f    NaN
e    2.5
d    NaN
c    3.5
b    4.5
a    NaN
dtype: float64
>>> b
f    0.0
e    1.0
d    2.0
c    3.0
b    4.0
a    NaN
dtype: float64
>>> np.where(pd.isnull(a),b,a)
array([0. , 2.5, 2. , 3.5, 4.5, nan])
>>> b[:2].combine_first(a[2:])
a    NaN
b    4.5
c    3.5
d    NaN
e    1.0
f    0.0
dtype: float64
>>> df1=DataFrame({'a':[1.,np.nan,5.,np.nan],
		   'b':[np.nan,2.,np.nan,6.],
		   'c':range(2,18,4)})
>>> df2=DataFrame({'a':[5.,4.,np.nan,3.,7.],
		   'b':[np.nan,3.,4.,6.,8.]})
>>> df1.combine_first(df2)
     a    b     c
0  1.0  NaN   2.0
1  4.0  2.0   6.0
2  5.0  4.0  10.0
3  3.0  6.0  14.0
4  7.0  8.0   NaN
>>> data=DataFrame(np.arange(6).reshape((2,3)),
		   index=pd.Index(['Ohio','Colorado'],name='state'),
		   columns=pd.Index(['one','two','three'],name='number'))
>>> data
number    one  two  three
state                    
Ohio        0    1      2
Colorado    3    4      5
>>> result=data.stack()
>>> result
state     number
Ohio      one       0
          two       1
          three     2
Colorado  one       3
          two       4
          three     5
dtype: int32
>>> #使用该数据的stack方法即可将列转换为行
>>> result.unstack()
number    one  two  three
state                    
Ohio        0    1      2
Colorado    3    4      5
>>> #用unstack即可将数据重新排列为DataFrame
>>> result.unstack(0)
state   Ohio  Colorado
number                
one        0         3
two        1         4
three      2         5
>>> result.unstack('state')
state   Ohio  Colorado
number                
one        0         3
two        1         4
three      2         5
>>> s1=Series([0,1,2,3],index=['a','b','c','d'])
>>> s2=Series([4,5,6],index=['c','d','e'])
>>> data2=pd.concat([s1,s2],keys=['one','two'])
>>> data2.unstack()
       a    b    c    d    e
one  0.0  1.0  2.0  3.0  NaN
two  NaN  NaN  4.0  5.0  6.0
>>> data2.unstack().stack()
one  a    0.0
     b    1.0
     c    2.0
     d    3.0
two  c    4.0
     d    5.0
     e    6.0
dtype: float64
>>> #stack默认滤除缺失数据
>>> data2.unstack().stack(dropna=False)
one  a    0.0
     b    1.0
     c    2.0
     d    3.0
     e    NaN
two  a    NaN
     b    NaN
     c    4.0
     d    5.0
     e    6.0
dtype: float64
>>> df=DataFrame({'left':result,'right':result+5},columns=pd.Index(['left','right'],name='side'))
>>> df
side             left  right
state    number             
Ohio     one        0      5
         two        1      6
         three      2      7
Colorado one        3      8
         two        4      9
         three      5     10
>>> df.unstack('state')
side   left          right         
state  Ohio Colorado  Ohio Colorado
number                             
one       0        3     5        8
two       1        4     6        9
three     2        5     7       10
>>> df.unstack('state').stack('side')
state         Colorado  Ohio
number side                 
one    left          3     0
       right         8     5
two    left          4     1
       right         9     6
three  left          5     2
       right        10     7
>>> data=pd.DataFrame({"k1":["one","two"]*3+["two"],"k2":[1,1,2,3,3,4,4]})
>>> data
    k1  k2
0  one   1
1  two   1
2  one   2
3  two   3
4  one   3
5  two   4
6  two   4
>>> data.duplicated()
0    False
1    False
2    False
3    False
4    False
5    False
6     True
dtype: bool
>>> #DataFrame的duplicated方法返回一个布尔型的Series，表示各行是否是重复行（前面出现过的行
>>> data.drop_duplicates()
    k1  k2
0  one   1
1  two   1
2  one   2
3  two   3
4  one   3
5  two   4
>>> data['v1']=range(7)
>>> data.drop_duplicates(['k1'])
    k1  k2  v1
0  one   1   0
1  two   1   1
>>> data.drop
<bound method DataFrame.drop of     k1  k2  v1
0  one   1   0
1  two   1   1
2  one   2   2
3  two   3   3
4  one   3   4
5  two   4   5
6  two   4   6>
>>> data.drop_duplicates(['k1','k2'])
    k1  k2  v1
0  one   1   0
1  two   1   1
2  one   2   2
3  two   3   3
4  one   3   4
5  two   4   5
>>> data.drop_duplicates(['k1','k2'],keep='last')
    k1  k2  v1
0  one   1   0
1  two   1   1
2  one   2   2
3  two   3   3
4  one   3   4
6  two   4   6
>>> data=pd.DataFrame({'food':['bacon','pulled pork','bacon','Pastrami','corned beef','Bacon','Pastrami','honey ham','nova lox'],'ounces':[4,3,12,6,7.5,8,3,5,6]})
>>> data
          food  ounces
0        bacon     4.0
1  pulled pork     3.0
2        bacon    12.0
3     Pastrami     6.0
4  corned beef     7.5
5        Bacon     8.0
6     Pastrami     3.0
7    honey ham     5.0
8     nova lox     6.0
>>> meat_to_animal={'bacon':'pig','pulled pork':'pig','pastrami':'cow','corned beef':'cow','honey ham':'pig','nova lox':'salmon'}
>>> lowercased=data['food'].str.lower()
>>> lowercased
0          bacon
1    pulled pork
2          bacon
3       pastrami
4    corned beef
5          bacon
6       pastrami
7      honey ham
8       nova lox
Name: food, dtype: object
>>> data['animal']=lowercased.map(meat_to_animal)
>>> data
          food  ounces  animal
0        bacon     4.0     pig
1  pulled pork     3.0     pig
2        bacon    12.0     pig
3     Pastrami     6.0     cow
4  corned beef     7.5     cow
5        Bacon     8.0     pig
6     Pastrami     3.0     cow
7    honey ham     5.0     pig
8     nova lox     6.0  salmon
>>> data['food'].map(lambda x:meat_to_animal[x.lower()])
0       pig
1       pig
2       pig
3       cow
4       cow
5       pig
6       cow
7       pig
8    salmon
Name: food, dtype: object
>>> data=pd.Series([1.,-999,2.,-999,-1000,3])
>>> data
0       1.0
1    -999.0
2       2.0
3    -999.0
4   -1000.0
5       3.0
dtype: float64
>>> data.replace(-999,np.nan)
0       1.0
1       NaN
2       2.0
3       NaN
4   -1000.0
5       3.0
dtype: float64
>>> data.replace([-999,-1000],[np.nan,0])
0    1.0
1    NaN
2    2.0
3    NaN
4    0.0
5    3.0
dtype: float64
>>> data.replace([-999,-1000],np.nan)
0    1.0
1    NaN
2    2.0
3    NaN
4    NaN
5    3.0
dtype: float64
>>> data.replace({-999:np.nan,-1000:0})
0    1.0
1    NaN
2    2.0
3    NaN
4    0.0
5    3.0
dtype: float64
>>> data=pd.DataFrame(np.arange(12).reshape((3,4)),index=['Ohio','Colorado','New York'],columns=['one','two','three','four'])
>>> data
          one  two  three  four
Ohio        0    1      2     3
Colorado    4    5      6     7
New York    8    9     10    11
>>> transform=lambda x:x[:4].upper()
>>> data.index.map(transform)
Index(['OHIO', 'COLO', 'NEW '], dtype='object')
>>> #轴索引修改
>>> data.index=data.index.map(transform)
>>> data
      one  two  three  four
OHIO    0    1      2     3
COLO    4    5      6     7
NEW     8    9     10    11
>>> data.rename(index=str.title,columns=str.upper)
      ONE  TWO  THREE  FOUR
Ohio    0    1      2     3
Colo    4    5      6     7
New     8    9     10    11
>>> data.rename(index={'OHIO':'INDIANA'},columns={'three':'peekaboo'})
         one  two  peekaboo  four
INDIANA    0    1         2     3
COLO       4    5         6     7
NEW        8    9        10    11
>>> data.rename(index={'OHIO':'INDIANA'},inplace=True)
>>> data
         one  two  three  four
INDIANA    0    1      2     3
COLO       4    5      6     7
NEW        8    9     10    11
>>> ages=[20,22,25,27,21,23,37,31,61,45,41,32]
>>> bins=[18,25,35,60,100]
>>> cats=pd.cut(ages,bins)
>>> cats
[(18, 25], (18, 25], (18, 25], (25, 35], (18, 25], ..., (25, 35], (60, 100], (35, 60], (35, 60], (25, 35]]
Length: 12
Categories (4, interval[int64]): [(18, 25] < (25, 35] < (35, 60] < (60, 100]]
>>> cats.codes
array([0, 0, 0, 1, 0, 0, 2, 1, 3, 2, 2, 1], dtype=int8)
>>> cats.categories
IntervalIndex([(18, 25], (25, 35], (35, 60], (60, 100]],
              closed='right',
              dtype='interval[int64]')
>>> pd.value_counts(cats)
(18, 25]     5
(35, 60]     3
(25, 35]     3
(60, 100]    1
dtype: int64
>>> pd.cut(ages,[18,26,36,61,100],right=False)
[[18, 26), [18, 26), [18, 26), [26, 36), [18, 26), ..., [26, 36), [61, 100), [36, 61), [36, 61), [26, 36)]
Length: 12
Categories (4, interval[int64]): [[18, 26) < [26, 36) < [36, 61) < [61, 100)]
>>> #哪边是闭端可以通过right=False进行修改
>>> group_names=['Youth','YoungAdult','MiddleAged','Senior']
>>> pd.cut(ages,bins,labels=group_names)
[Youth, Youth, Youth, YoungAdult, Youth, ..., YoungAdult, Senior, MiddleAged, MiddleAged, YoungAdult]
Length: 12
Categories (4, object): [Youth < YoungAdult < MiddleAged < Senior]
>>> data=np.random.randn(20)
>>> data
array([-0.29997836,  0.45104818,  0.25799107,  1.60601473,  1.79351107,
       -2.0606261 ,  0.28685958, -0.00228017, -2.0704189 ,  0.45464935,
       -0.01464663,  0.25688272,  0.36880463, -1.06560587, -1.33109027,
       -0.1107627 ,  1.59453768, -1.04754334,  0.83912252, -0.31216463])
>>> pd.cut(data,4,precision=2)
[(-1.1, -0.14], (-0.14, 0.83], (-0.14, 0.83], (0.83, 1.79], (0.83, 1.79], ..., (-0.14, 0.83], (0.83, 1.79], (-1.1, -0.14], (0.83, 1.79], (-1.1, -0.14]]
Length: 20
Categories (4, interval[float64]): [(-2.07, -1.1] < (-1.1, -0.14] < (-0.14, 0.83] < (0.83, 1.79]]
>>> data=np.random.randn(1000)
>>> cats=pd.qcut(data,4)
>>> cats
[(0.000226, 0.677], (-3.185, -0.695], (0.677, 3.1], (0.677, 3.1], (0.000226, 0.677], ..., (0.677, 3.1], (0.000226, 0.677], (-3.185, -0.695], (0.000226, 0.677], (0.677, 3.1]]
Length: 1000
Categories (4, interval[float64]): [(-3.185, -0.695] < (-0.695, 0.000226] < (0.000226, 0.677] <
                                    (0.677, 3.1]]
>>> pd.value_counts(cats)
(0.677, 3.1]          250
(0.000226, 0.677]     250
(-0.695, 0.000226]    250
(-3.185, -0.695]      250
dtype: int64
>>> pd.qcut(data,[0,0.1,0.5,0.9,1.])
[(0.000226, 1.331], (-3.185, -1.275], (0.000226, 1.331], (0.000226, 1.331], (0.000226, 1.331], ..., (0.000226, 1.331], (0.000226, 1.331], (-3.185, -1.275], (0.000226, 1.331], (0.000226, 1.331]]
Length: 1000
Categories (4, interval[float64]): [(-3.185, -1.275] < (-1.275, 0.000226] < (0.000226, 1.331] <
                                    (1.331, 3.1]]
>>> data=pd.DataFrame(np.random.randn(1000,4))
>>> data.describe()
                 0            1            2            3
count  1000.000000  1000.000000  1000.000000  1000.000000
mean     -0.017200     0.033063     0.006971    -0.073231
std       1.007444     1.010421     1.060354     0.994654
min      -2.953618    -3.021222    -3.222788    -3.717752
25%      -0.679562    -0.641962    -0.742753    -0.747698
50%      -0.043524     0.055825     0.025145    -0.013840
75%       0.646200     0.734867     0.718169     0.632214
max       3.252478     3.001479     2.973103     2.664647
>>> col=data[2]
>>> col[np.abs(col)>3]
458   -3.222788
Name: 2, dtype: float64
>>> data[(np.abs(data)>3).any(1)]
            0         1         2         3
21  -0.206549 -3.021222 -0.346772 -1.611652
106  1.235482  0.736726 -1.491838 -3.717752
166 -1.483439  3.001479  1.356934 -0.423457
458  0.339622 -0.202714 -3.222788 -1.212373
795  3.252478 -0.523062 -1.268629 -1.579846
>>> data[np.abs(data)>3]=np.sign(data)*3
>>> data.describe()
                 0            1            2            3
count  1000.000000  1000.000000  1000.000000  1000.000000
mean     -0.017452     0.033083     0.007194    -0.072513
std       1.006655     1.010353     1.059698     0.992278
min      -2.953618    -3.000000    -3.000000    -3.000000
25%      -0.679562    -0.641962    -0.742753    -0.747698
50%      -0.043524     0.055825     0.025145    -0.013840
75%       0.646200     0.734867     0.718169     0.632214
max       3.000000     3.000000     2.973103     2.664647
>>> np.sign(data).head()
     0    1    2    3
0 -1.0  1.0 -1.0 -1.0
1  1.0  1.0  1.0  1.0
2 -1.0  1.0 -1.0  1.0
3  1.0  1.0  1.0 -1.0
4  1.0  1.0  1.0  1.0
>>> df=pd.DataFrame(np.arange(5*4).reshape((5,4)))
>>> sampler=np.random.permutation(5)
>>> sampler
array([4, 1, 0, 3, 2])
>>> df
    0   1   2   3
0   0   1   2   3
1   4   5   6   7
2   8   9  10  11
3  12  13  14  15
4  16  17  18  19
>>> df.take(sampler)
    0   1   2   3
4  16  17  18  19
1   4   5   6   7
0   0   1   2   3
3  12  13  14  15
2   8   9  10  11
>>> #take使得df按照新的sampler排序方法排序
>>> df.sample(n=3)
    0   1   2   3
2   8   9  10  11
1   4   5   6   7
4  16  17  18  19
>>> choices=pd.Series([5,7,-1,6,4])
>>> draws=choices.sample(n=10,replace=True)
>>> draws
4    4
4    4
1    7
0    5
4    4
4    4
0    5
1    7
0    5
4    4
dtype: int64
>>> #随机选取10个choices中的值，代替旧数组
>>> file='D:\python\pra\ex10.csv'
>>> mnames=['movie_id','title','genres']
>>> movies=pd.read_csv(file,sep='::',header=None,names=mnames)
>>> movies
                                             movie_id  title  genres
0                           movie_id,,title,,,,genres    NaN     NaN
1   1,,Toy Story (1995),,,,Animation|Children's|Co...    NaN     NaN
2   2,,Jumanji (1995),,,,Adventure|Children's|Fantasy    NaN     NaN
3        3,,Grumpier Old Men (1995),,,,Comedy|Romance    NaN     NaN
4         4,,Waiting to Exhale (1995),,,,Comedy|Drama    NaN     NaN
5     5,,Father of the Bride Part II (1995),,,,Comedy    NaN     NaN
6             6,,Heat (1995),,,,Action|Crime|Thriller    NaN     NaN
7                 7,,Sabrina (1995),,,,Comedy|Romance    NaN     NaN
8      8,,Tom and Huck (1995),,,,Adventure|Children's    NaN     NaN
9                    9,,Sudden Death (1995),,,,Action    NaN     NaN
10  10,,GoldenEye (1995),,,,Action|Adventure|Thriller    NaN     NaN				
>>> genres=pd.unique(all_genres)
>>> genres
array([], dtype=float64)
>>> zero_matrix=np.zeros((len(movies),len(genres))
SyntaxError: invalid syntax
>>> dummies=pd.DataFrame(zero_matrix.columns=genres)
			 
SyntaxError: keyword can't be an expression
>>> gen=movies.genres[0]
			 
>>> gen.split("|")
			 
Traceback (most recent call last):
  File "<pyshell#61>", line 1, in <module>
    gen.split("|")
AttributeError: 'numpy.float64' object has no attribute 'split'
>>> dummies.columns.get_indexer(gen.split("|"))
			 
Traceback (most recent call last):
  File "<pyshell#62>", line 1, in <module>
    dummies.columns.get_indexer(gen.split("|"))
AttributeError: 'numpy.float64' object has no attribute 'split'
>>> for i,gen in enumerate(movies.genres):
	indices=dummies.columns.get_indexer(gen.split("|"))
	dummies.iloc[i,indices]=1

			 
Traceback (most recent call last):
  File "<pyshell#66>", line 2, in <module>
    indices=dummies.columns.get_indexer(gen.split("|"))
AttributeError: 'float' object has no attribute 'split'
>>> np.random.seed(12345)
			 
>>> values=np.random.randn(10)
			 
>>> values
			 
array([-0.20470766,  0.47894334, -0.51943872, -0.5557303 ,  1.96578057,
        1.39340583,  0.09290788,  0.28174615,  0.76902257,  1.24643474])
>>> bins=[0,0.2,0.4,0.6,0.8,1]
			 
>>> pd.get_dummies(pd.cut(values,bins))
			 
   (0.0, 0.2]  (0.2, 0.4]  (0.4, 0.6]  (0.6, 0.8]  (0.8, 1.0]
0           0           0           0           0           0
1           0           0           1           0           0
2           0           0           0           0           0
3           0           0           0           0           0
4           0           0           0           0           0
5           0           0           0           0           0
6           1           0           0           0           0
7           0           1           0           0           0
8           0           0           0           1           0
9           0           0           0           0           0
>>> val='a,b,guido'
			 
>>> val.split(',')
			 
['a', 'b', 'guido']
>>> pieces=[x.strip() for x in val.split(',')]
			 
>>> pieces
			 
['a', 'b', 'guido']
>>> first,second,third=pieces
			 
>>> first+'::'+second+'::'+third
			 
'a::b::guido'
>>> '::'.join(pieces)
			 
'a::b::guido'
>>> 'guido' in val
			 
True
>>> val.index(',')
			 
1
>>> val.find(':')
			 
-1
>>> #如果找不到字符串，find返回-1，index返回异常
			 
>>> val.index(':')
			 
Traceback (most recent call last):
  File "<pyshell#83>", line 1, in <module>
    val.index(':')
ValueError: substring not found
>>> val.count(',')
			 
2
>>> val.replace(',','::')
			 
'a::b::guido'
>>> val.replace(',','')
			 
'abguido'
>>> import re
			 
>>> text="foo bar\t baz   \tqux"
			 
>>> re.split("\s+",text)
			 
['foo', 'bar', 'baz', 'qux']
>>> regex=re.compile("\s+")
			 
>>> regex.split(text)
			 
['foo', 'bar', 'baz', 'qux']
>>> regex.findall(text)
			 
[' ', '\t ', '   \t']
>>> text="""Dave dave@google.com
Steve steve@gmail.com
Rob rob@gmail.com
Ryan ryan@yahoo.com
"""
>>> pattern=r'[A-Z0-9.%+-]+@[A-Z0-9.-]+\.[A-Z]{2,4}'
			 
>>> regex=re.compile(pattern,flags=re.IGNORECASE)
			 
>>> regex.findall(text)
			 
['dave@google.com', 'steve@gmail.com', 'rob@gmail.com', 'ryan@yahoo.com']
>>> m=regex.search(text)
			 
>>> m
			 
<_sre.SRE_Match object; span=(5, 20), match='dave@google.com'>
>>> text[m.start():m.end()]
			 
'dave@google.com'
>>> print(regex.match(text))
			 
None
>>> print(regex.sub('REDACTED',text))
			 
Dave REDACTED
Steve REDACTED
Rob REDACTED
Ryan REDACTED

>>> pattern = r'([A-Z0-9._%+-]+)@([A-Z0-9.-]+)\.([A-Z]{2,4})'
			 
>>> regex=re.compile(pattern,flags=re.IGNORECASE)
			 
>>> m=regex.match('wesm@bright.net')
			 
>>> m.groups()
			 
('wesm', 'bright', 'net')
>>> regex.findall(text)
			 
[('dave', 'google', 'com'), ('steve', 'gmail', 'com'), ('rob', 'gmail', 'com'), ('ryan', 'yahoo', 'com')]
>>> data={'Dave':'dave@google.com','Steve':'steve@gmail.com','Rob':'"rob@gmail.com','Wes':np.nan}
>>> data=pd.Series(data)
			 
>>> data
			 
Dave     dave@google.com
Steve    steve@gmail.com
Rob       "rob@gmail.com
Wes                  NaN
dtype: object
>>> data.isnull()
			 
Dave     False
Steve    False
Rob      False
Wes       True
dtype: bool
>>> data.str.contains('gmail')
			 
Dave     False
Steve     True
Rob       True
Wes        NaN
dtype: object
>>> pattern
			 
'([A-Z0-9._%+-]+)@([A-Z0-9.-]+)\\.([A-Z]{2,4})'
>>> data.str.findall(pattern,flags=re.IGNORECASE)
			 
Dave     [(dave, google, com)]
Steve    [(steve, gmail, com)]
Rob        [(rob, gmail, com)]
Wes                        NaN
dtype: object
>>> matches=data.str.match(pattern,flags=re.IGNORECASE)
			 
>>> matches
			 
Dave      True
Steve     True
Rob      False
Wes        NaN
dtype: object
>>> matches.str.get(1)
			 
Dave    NaN
Steve   NaN
Rob     NaN
Wes     NaN
dtype: float64
>>> matches.str[0]
			 
Dave    NaN
Steve   NaN
Rob     NaN
Wes     NaN
dtype: float64
>>> data.str[:5]
			 
Dave     dave@
Steve    steve
Rob      "rob@
Wes        NaN
dtype: object












































