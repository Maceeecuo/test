>>> from pandas import Series,DataFrame
>>> import pandas as pd
>>> import numpy as np
>>> df=pd.DataFrame({'key1':['a','a','b','b','a'],
		     'key2':['one','two','one','two','one'],
		     'data1':np.random.randn(5),
		     'data2':np.random.randn(5)})
>>> df
  key1 key2     data1     data2
0    a  one  1.536150 -0.159347
1    a  two  1.145417  1.468526
2    b  one -0.649589 -0.960185
3    b  two  2.097288  0.153509
4    a  one -0.247084  1.503358
>>> grouped=df['data1'].groupby(df['key1'])
>>> grouped
<pandas.core.groupby.generic.SeriesGroupBy object at 0x0000000002FB8CF8>
>>> grouped.mean()
key1
a    0.811494
b    0.723849
Name: data1, dtype: float64
>>> means=df['data1'].groupby([df['key1'],df['key2']]).mean()
>>> means
key1  key2
a     one     0.644533
      two     1.145417
b     one    -0.649589
      two     2.097288
Name: data1, dtype: float64
>>> means.unstack()
key2       one       two
key1                    
a     0.644533  1.145417
b    -0.649589  2.097288
>>> states=np.array(['Ohio','California','California','Ohio','Ohio'])
>>> years=np.array([2005,2005,2006,2005,2006])
>>> df['data1'].groupby([states,years]).mean()
California  2005    1.145417
            2006   -0.649589
Ohio        2005    1.816719
            2006   -0.247084
Name: data1, dtype: float64
>>> df.groupby('key1').mean()
         data1     data2
key1                    
a     0.811494  0.937512
b     0.723849 -0.403338
>>> df.groupby(['key1','key2']).mean()
              data1     data2
key1 key2                    
a    one   0.644533  0.672005
     two   1.145417  1.468526
b    one  -0.649589 -0.960185
     two   2.097288  0.153509
>>> df.groupby(['key1','key2']).size()
key1  key2
a     one     2
      two     1
b     one     1
      two     1
dtype: int64
>>> for name,group in df.groupby('key1'):
	print(name)
	print(group)

a
  key1 key2     data1     data2
0    a  one  1.536150 -0.159347
1    a  two  1.145417  1.468526
4    a  one -0.247084  1.503358
b
  key1 key2     data1     data2
2    b  one -0.649589 -0.960185
3    b  two  2.097288  0.153509
>>> for (k1,k2),group in df.groupby(['key1','key2']):
	print((k1,k2))
	print(group)

	
('a', 'one')
  key1 key2     data1     data2
0    a  one  1.536150 -0.159347
4    a  one -0.247084  1.503358
('a', 'two')
  key1 key2     data1     data2
1    a  two  1.145417  1.468526
('b', 'one')
  key1 key2     data1     data2
2    b  one -0.649589 -0.960185
('b', 'two')
  key1 key2     data1     data2
3    b  two  2.097288  0.153509
>>> pieces=dict(list(df.groupby('key1')))
>>> pieces['b']
  key1 key2     data1     data2
2    b  one -0.649589 -0.960185
3    b  two  2.097288  0.153509
>>> #groupby默认在axis=0（行）上进行分组
>>> df.types
Traceback (most recent call last):
  File "<pyshell#32>", line 1, in <module>
    df.types
  File "D:\python\python3.6.6\lib\site-packages\pandas\core\generic.py", line 5067, in __getattr__
    return object.__getattribute__(self, name)
AttributeError: 'DataFrame' object has no attribute 'types'
>>> grouped=df.groupby(df.dtypes,axis=1)
>>> for dtype,group in grouped:
	print(dtype)
	print(group)

	
float64
      data1     data2
0  1.536150 -0.159347
1  1.145417  1.468526
2 -0.649589 -0.960185
3  2.097288  0.153509
4 -0.247084  1.503358
object
  key1 key2
0    a  one
1    a  two
2    b  one
3    b  two
4    a  one
>>> df.groupby('key1')['data1']
<pandas.core.groupby.generic.SeriesGroupBy object at 0x00000000055615C0>
>>> df.groupby('key1')[['data2']]
<pandas.core.groupby.generic.DataFrameGroupBy object at 0x0000000005561208>
>>> df['data1'].groupby(df['key1'])		   
<pandas.core.groupby.generic.SeriesGroupBy object at 0x0000000002FB8C50>
<pandas.core.groupby.generic.SeriesGroupBy object at 0x0000000002FB8C50>
>>> df[['data2']].groupby(df['key1'])
			   
<pandas.core.groupby.generic.DataFrameGroupBy object at 0x0000000005561198>
>>> df.groupby(['key1','key2'])[['data2']].mean()			   
              data2
key1 key2          
a    one   0.672005
     two   1.468526
b    one  -0.960185
     two   0.153509
>>> s_grouped=df.groupby(['key1','key2'])['data2']
>>> s_grouped
<pandas.core.groupby.generic.SeriesGroupBy object at 0x0000000005674780>
>>> s_grouped.mean()
			   
key1  key2
a     one     0.672005
      two     1.468526
b     one    -0.960185
      two     0.153509
Name: data2, dtype: float64
>>> people=pd.DataFrame(np.random.randn(5,5),columns=['a','b','c','d','e'],index=['Joe','Steve','Wes','Jim','Travis'])
			   
>>> people.iloc[2:3,[1,2]]=np.nan
			   
>>> people
			   
               a         b         c         d         e
Joe    -1.440956  0.483474 -0.310328 -1.137561 -1.312502
Steve  -0.587413 -0.590840 -0.161274 -0.498062  0.358051
Wes    -1.753277       NaN       NaN  0.048470  1.736482
Jim     0.746721  0.172708  0.798516  0.825998  1.177195
Travis -0.435557 -1.011992  0.107068 -0.240252  0.969837
>>> mapping={'a':'red','b':'red','c':'blue','d':'blue','e':'red','f':'orange'}
>>> by_column=people.groupby(mapping,axis=1)
			   
>>> by_column.sum()
			   
            blue       red
Joe    -1.447889 -2.269984
Steve  -0.659336 -0.820203
Wes     0.048470 -0.016795
Jim     1.624513  2.096625
Travis -0.133184 -0.477712
>>> map_series=pd.Series(mapping)
			   
>>> map_series
			   
a       red
b       red
c      blue
d      blue
e       red
f    orange
dtype: object
>>> people.groupby(map_series,axis=1).count()
			   
        blue  red
Joe        2    3
Steve      2    3
Wes        1    2
Jim        2    3
Travis     2    3
>>> people.groupby(len).sum()
			   
          a         b         c         d         e
3 -2.447512  0.656182  0.488188 -0.263094  1.601176
5 -0.587413 -0.590840 -0.161274 -0.498062  0.358051
6 -0.435557 -1.011992  0.107068 -0.240252  0.969837
>>> key_list=['one','one','one','two','two']
>>> people.groupby([len,key_list]).min()
		   
              a         b         c         d         e
3 one -1.753277  0.483474 -0.310328 -1.137561 -1.312502
  two  0.746721  0.172708  0.798516  0.825998  1.177195
5 one -0.587413 -0.590840 -0.161274 -0.498062  0.358051
6 two -0.435557 -1.011992  0.107068 -0.240252  0.969837
>>> columns=pd.MultiIndex.from_arrays([['US','US','US','JP','JP'],[1,3,5,1,3]],names=['cty','tenor'])
		   
>>> hier_df=pd.DataFrame(np.random.randn(4,5),columns=columns)
		   
>>> hier_df
		   
cty          US                            JP          
tenor         1         3         5         1         3
0     -0.403766  0.936847 -1.125547 -0.070928  1.382745
1     -0.140367 -0.675789 -2.260039  3.987206  0.365437
2      1.859973 -0.388325 -0.208550  1.520165  0.642543
3     -0.822489 -0.951763 -0.779612 -0.873974  1.118389
>>> hier_df.groupby(level='cty',axis=1).count()
		   
cty  JP  US
0     2   3
1     2   3
2     2   3
3     2   3
>>> df
		   
  key1 key2     data1     data2
0    a  one  1.536150 -0.159347
1    a  two  1.145417  1.468526
2    b  one -0.649589 -0.960185
3    b  two  2.097288  0.153509
4    a  one -0.247084  1.503358
>>> grouped=df.groupby('key1')
		   
>>> grouped['data1'].quantile(0.9)
		   
key1
a    1.458003
b    1.822600
Name: data1, dtype: float64
>>> def peak_to_peak(arr):
		   return arr.max()-arr.min()

		   
>>> grouped.agg(peak_to_peak)
		   
         data1     data2
key1                    
a     1.783234  1.662705
b     2.746877  1.113695
>>> grouped.describe()
		   
     data1                      ...     data2                    
     count      mean       std  ...       50%       75%       max
key1                            ...                              
a      3.0  0.811494  0.937341  ...  1.468526  1.485942  1.503358
b      2.0  0.723849  1.942335  ... -0.403338 -0.124914  0.153509

[2 rows x 16 columns]
>>> file='D:\python\pra\ex14.csv'
>>> tips=pd.read_csv(file)
>>> tips['tip_pct']=tips['tip']/tips['total_bill']
>>> tips[:6]
   total_bill   tip smoker  day    time  size   tip_pct
0       16.99  1.01     No  Sun  Dinner     2  0.059447
1       10.34  1.66     No  Sun  Dinner     3  0.160542
2       21.01  3.50     No  Sun  Dinner     3  0.166587
3       23.68  3.31     No  Sun  Dinner     2  0.139780
4       24.59  3.61     No  Sun  Dinner     4  0.146808
5       25.29  4.71     No  Sun  Dinner     4  0.186240
>>> grouped=tips.groupby(['day','smoker'])
>>> grouped_pct=grouped['tip_pct']
>>> grouped_pct.agg('mean')
day   smoker
Fri   No        0.151650
      Yes       0.174783
Sat   No        0.158048
      Yes       0.147906
Sun   No        0.160113
      Yes       0.187250
Thur  No        0.160298
      Yes       0.163863
Name: tip_pct, dtype: float64
>>> def peak_to_peak(arr):
	return arr.max()-arr.min()

>>> grouped_pct.agg(['mean','std',peak_to_peak])
                 mean       std  peak_to_peak
day  smoker                                  
Fri  No      0.151650  0.028123      0.067349
     Yes     0.174783  0.051293      0.159925
Sat  No      0.158048  0.039767      0.235193
     Yes     0.147906  0.061375      0.290095
Sun  No      0.160113  0.042347      0.193226
     Yes     0.187250  0.154134      0.644685
Thur No      0.160298  0.038774      0.193350
     Yes     0.163863  0.039389      0.151240
>>> grouped_pct.agg([('foo','mean',),('bar',np.std)])
                  foo       bar
day  smoker                    
Fri  No      0.151650  0.028123
     Yes     0.174783  0.051293
Sat  No      0.158048  0.039767
     Yes     0.147906  0.061375
Sun  No      0.160113  0.042347
     Yes     0.187250  0.154134
Thur No      0.160298  0.038774
     Yes     0.163863  0.039389
>>> functions=['count','mean','max']
>>> result=grouped['tip_pct','total_bill'].agg(functions)
>>> result
            tip_pct                     total_bill                  
              count      mean       max      count       mean    max
day  smoker                                                         
Fri  No           4  0.151650  0.187735          4  18.420000  22.75
     Yes         15  0.174783  0.263480         15  16.813333  40.17
Sat  No          45  0.158048  0.291990         45  19.661778  48.33
     Yes         42  0.147906  0.325733         42  21.276667  50.81
Sun  No          57  0.160113  0.252672         57  20.506667  48.17
     Yes         19  0.187250  0.710345         19  24.120000  45.35
Thur No          45  0.160298  0.266312         45  17.113111  41.19
     Yes         17  0.163863  0.241255         17  19.190588  43.11
>>> result['tip_pct']
             count      mean       max
day  smoker                           
Fri  No          4  0.151650  0.187735
     Yes        15  0.174783  0.263480
Sat  No         45  0.158048  0.291990
     Yes        42  0.147906  0.325733
Sun  No         57  0.160113  0.252672
     Yes        19  0.187250  0.710345
Thur No         45  0.160298  0.266312
     Yes        17  0.163863  0.241255
>>> ftuples=[('Durchschnitt','mean'),('Abweichung',np.var)]
>>> grouped['tip_pct','total_bill'].agg(ftuples)
                 tip_pct              total_bill            
            Durchschnitt Abweichung Durchschnitt  Abweichung
day  smoker                                                 
Fri  No         0.151650   0.000791    18.420000   25.596333
     Yes        0.174783   0.002631    16.813333   82.562438
Sat  No         0.158048   0.001581    19.661778   79.908965
     Yes        0.147906   0.003767    21.276667  101.387535
Sun  No         0.160113   0.001793    20.506667   66.099980
     Yes        0.187250   0.023757    24.120000  109.046044
Thur No         0.160298   0.001503    17.113111   59.625081
     Yes        0.163863   0.001551    19.190588   69.808518
>>> grouped.agg({'tip':np.max,'size':'sum'})
               tip  size
day  smoker             
Fri  No       3.50     9
     Yes      4.73    31
Sat  No       9.00   115
     Yes     10.00   104
Sun  No       6.00   167
     Yes      6.50    49
Thur No       6.70   112
     Yes      5.00    40
>>> tips.groupby(['day','smoker'],as_index=False).mean()
    day smoker  total_bill       tip      size   tip_pct
0   Fri     No   18.420000  2.812500  2.250000  0.151650
1   Fri    Yes   16.813333  2.714000  2.066667  0.174783
2   Sat     No   19.661778  3.102889  2.555556  0.158048
3   Sat    Yes   21.276667  2.875476  2.476190  0.147906
4   Sun     No   20.506667  3.167895  2.929825  0.160113
5   Sun    Yes   24.120000  3.516842  2.578947  0.187250
6  Thur     No   17.113111  2.673778  2.488889  0.160298
7  Thur    Yes   19.190588  3.030000  2.352941  0.163863
>>> def top(df,n=5,column='tip_pct'):
	return df.sort_values(by=column)[-n:]

>>> top(tips,n=6)
     total_bill   tip smoker  day    time  size   tip_pct
109       14.31  4.00    Yes  Sat  Dinner     2  0.279525
183       23.17  6.50    Yes  Sun  Dinner     4  0.280535
232       11.61  3.39     No  Sat  Dinner     2  0.291990
67         3.07  1.00    Yes  Sat  Dinner     1  0.325733
178        9.60  4.00    Yes  Sun  Dinner     2  0.416667
172        7.25  5.15    Yes  Sun  Dinner     2  0.710345
>>> tips.groupby('smoker').apply(top)
            total_bill   tip smoker   day    time  size   tip_pct
smoker                                                           
No     88        24.71  5.85     No  Thur   Lunch     2  0.236746
       185       20.69  5.00     No   Sun  Dinner     5  0.241663
       51        10.29  2.60     No   Sun  Dinner     2  0.252672
       149        7.51  2.00     No  Thur   Lunch     2  0.266312
       232       11.61  3.39     No   Sat  Dinner     2  0.291990
Yes    109       14.31  4.00    Yes   Sat  Dinner     2  0.279525
       183       23.17  6.50    Yes   Sun  Dinner     4  0.280535
       67         3.07  1.00    Yes   Sat  Dinner     1  0.325733
       178        9.60  4.00    Yes   Sun  Dinner     2  0.416667
       172        7.25  5.15    Yes   Sun  Dinner     2  0.710345
>>> tips.groupby(['smoker','day']).apply(top,n=1,column='total_bill')
                 total_bill    tip smoker   day    time  size   tip_pct
smoker day                                                             
No     Fri  94        22.75   3.25     No   Fri  Dinner     2  0.142857
       Sat  212       48.33   9.00     No   Sat  Dinner     4  0.186220
       Sun  156       48.17   5.00     No   Sun  Dinner     6  0.103799
       Thur 142       41.19   5.00     No  Thur   Lunch     5  0.121389
Yes    Fri  95        40.17   4.73    Yes   Fri  Dinner     4  0.117750
       Sat  170       50.81  10.00    Yes   Sat  Dinner     3  0.196812
       Sun  182       45.35   3.50    Yes   Sun  Dinner     3  0.077178
       Thur 197       43.11   5.00    Yes  Thur   Lunch     4  0.115982
>>> result=tips.groupby('smoker')['tip_pct'].describe()
>>> result
        count      mean       std  ...       50%       75%       max
smoker                             ...                              
No      151.0  0.159328  0.039910  ...  0.155625  0.185014  0.291990
Yes      93.0  0.163196  0.085119  ...  0.153846  0.195059  0.710345

[2 rows x 8 columns]
>>> result.unstack('smoker')
       smoker
count  No        151.000000
       Yes        93.000000
mean   No          0.159328
       Yes         0.163196
std    No          0.039910
       Yes         0.085119
min    No          0.056797
       Yes         0.035638
25%    No          0.136906
       Yes         0.106771
50%    No          0.155625
       Yes         0.153846
75%    No          0.185014
       Yes         0.195059
max    No          0.291990
       Yes         0.710345
dtype: float64
>>> f=lambda x:x.describe()
>>> grouped.apply(f)
                   total_bill        tip       size    tip_pct
day  smoker                                                   
Fri  No     count    4.000000   4.000000   4.000000   4.000000
            mean    18.420000   2.812500   2.250000   0.151650
            std      5.059282   0.898494   0.500000   0.028123
            min     12.460000   1.500000   2.000000   0.120385
            25%     15.100000   2.625000   2.000000   0.137239
            50%     19.235000   3.125000   2.000000   0.149241
            75%     22.555000   3.312500   2.250000   0.163652
            max     22.750000   3.500000   3.000000   0.187735
     Yes    count   15.000000  15.000000  15.000000  15.000000
            mean    16.813333   2.714000   2.066667   0.174783
            std      9.086388   1.077668   0.593617   0.051293
            min      5.750000   1.000000   1.000000   0.103555
            25%     11.690000   1.960000   2.000000   0.133739
            50%     13.420000   2.500000   2.000000   0.173913
            75%     18.665000   3.240000   2.000000   0.209240
            max     40.170000   4.730000   4.000000   0.263480
Sat  No     count   45.000000  45.000000  45.000000  45.000000
            mean    19.661778   3.102889   2.555556   0.158048
            std      8.939181   1.642088   0.784960   0.039767
            min      7.250000   1.000000   1.000000   0.056797
            25%     14.730000   2.010000   2.000000   0.136240
            50%     17.820000   2.750000   2.000000   0.150152
            75%     20.650000   3.390000   3.000000   0.183915
            max     48.330000   9.000000   4.000000   0.291990
     Yes    count   42.000000  42.000000  42.000000  42.000000
            mean    21.276667   2.875476   2.476190   0.147906
            std     10.069138   1.630580   0.862161   0.061375
            min      3.070000   1.000000   1.000000   0.035638
            25%     13.405000   2.000000   2.000000   0.091797
            50%     20.390000   2.690000   2.000000   0.153624
...                       ...        ...        ...        ...
Sun  No     std      8.130189   1.224785   1.032674   0.042347
            min      8.770000   1.010000   2.000000   0.059447
            25%     14.780000   2.000000   2.000000   0.139780
            50%     18.430000   3.020000   3.000000   0.161665
            75%     25.000000   3.920000   4.000000   0.185185
            max     48.170000   6.000000   6.000000   0.252672
     Yes    count   19.000000  19.000000  19.000000  19.000000
            mean    24.120000   3.516842   2.578947   0.187250
            std     10.442511   1.261151   0.901591   0.154134
            min      7.250000   1.500000   2.000000   0.065660
            25%     17.165000   3.000000   2.000000   0.097723
            50%     23.100000   3.500000   2.000000   0.138122
            75%     32.375000   4.000000   3.000000   0.215325
            max     45.350000   6.500000   5.000000   0.710345
Thur No     count   45.000000  45.000000  45.000000  45.000000
            mean    17.113111   2.673778   2.488889   0.160298
            std      7.721728   1.282964   1.179796   0.038774
            min      7.510000   1.250000   1.000000   0.072961
            25%     11.690000   1.800000   2.000000   0.137741
            50%     15.950000   2.180000   2.000000   0.153492
            75%     20.270000   3.000000   2.000000   0.184843
            max     41.190000   6.700000   6.000000   0.266312
     Yes    count   17.000000  17.000000  17.000000  17.000000
            mean    19.190588   3.030000   2.352941   0.163863
            std      8.355149   1.113491   0.701888   0.039389
            min     10.340000   2.000000   2.000000   0.090014
            25%     13.510000   2.000000   2.000000   0.148038
            50%     16.470000   2.560000   2.000000   0.153846
            75%     19.810000   4.000000   2.000000   0.194837
            max     43.110000   5.000000   4.000000   0.241255

[64 rows x 4 columns]
>>> tips.groupby('smoker',group_keys=False).apply(top)
     total_bill   tip smoker   day    time  size   tip_pct
88        24.71  5.85     No  Thur   Lunch     2  0.236746
185       20.69  5.00     No   Sun  Dinner     5  0.241663
51        10.29  2.60     No   Sun  Dinner     2  0.252672
149        7.51  2.00     No  Thur   Lunch     2  0.266312
232       11.61  3.39     No   Sat  Dinner     2  0.291990
109       14.31  4.00    Yes   Sat  Dinner     2  0.279525
183       23.17  6.50    Yes   Sun  Dinner     4  0.280535
67         3.07  1.00    Yes   Sat  Dinner     1  0.325733
178        9.60  4.00    Yes   Sun  Dinner     2  0.416667
172        7.25  5.15    Yes   Sun  Dinner     2  0.710345
>>> frame=pd.DataFrame({'data1':np.random.randn(1000),
			'data2':np.random.randn(1000)})
>>> quartiles=pd.cut(frame.data1,4)
>>> quartiles[:10]
0    (-1.853, -0.319]
1     (-0.319, 1.215]
2     (-0.319, 1.215]
3      (1.215, 2.749]
4    (-1.853, -0.319]
5     (-0.319, 1.215]
6    (-1.853, -0.319]
7     (-0.319, 1.215]
8    (-1.853, -0.319]
9     (-0.319, 1.215]
Name: data1, dtype: category
Categories (4, interval[float64]): [(-3.393, -1.853] < (-1.853, -0.319] < (-0.319, 1.215] <
                                    (1.215, 2.749]]
>>> def get_stats(group):
	return{'min':group.min(),'max':group.max(),'count':group.count(),'mean':		group.mean()}

>>> grouped=frame.data2.groupby(quartiles)
>>> grouped.apply(get_stats).unstack()
                  count       max      mean       min
data1                                                
(-3.393, -1.853]   37.0  2.188095  0.147096 -1.340250
(-1.853, -0.319]  334.0  3.080357 -0.061646 -2.798341
(-0.319, 1.215]   513.0  3.565056  0.015422 -3.195236
(1.215, 2.749]    116.0  2.272575 -0.020101 -3.002138
>>> grouping=pd.qcut(frame.data1,10,labels=False)
>>> grouped=frame.data2.groupby(grouping)
>>> grouped.apply(get_stats).unstack()
       count       max      mean       min
data1                                     
0      100.0  2.457694  0.171359 -2.012314
1      100.0  2.814799 -0.160352 -2.027281
2      100.0  3.080357 -0.064555 -2.798341
3      100.0  2.169957 -0.127208 -2.394483
4      100.0  2.668277 -0.075201 -3.195236
5      100.0  2.166386  0.167581 -2.258811
6      100.0  3.565056  0.164672 -1.957359
7      100.0  2.057231 -0.086912 -2.685742
8      100.0  2.777569 -0.039647 -1.996672
9      100.0  2.272575 -0.045410 -3.002138
>>> s=pd.Series(np.random.randn(6))
>>> s[::2]=np.nan
>>> s
0         NaN
1    0.786685
2         NaN
3   -0.337087
4         NaN
5   -1.622295
dtype: float64
>>> s.fillna(s.mean())
0   -0.390899
1    0.786685
2   -0.390899
3   -0.337087
4   -0.390899
5   -1.622295
dtype: float64
>>> states={'Ohio','New York','Vermont','Florida','Oregon','Nevada','California'	,'Idaho'}
>>> group_key=['East']*4+['West']*4
>>> data=pd.Series(np.random.randn(8),index=states)
>>> data
Oregon       -0.157550
Idaho        -0.459462
Nevada        0.747336
Ohio          1.472126
Vermont      -0.629245
Florida       1.583768
California    0.242058
New York     -1.701119
dtype: float64
>>> data[['Vermont','Nevada','Idaho']]=np.nan
>>> data
Oregon       -0.157550
Idaho              NaN
Nevada             NaN
Ohio          1.472126
Vermont            NaN
Florida       1.583768
California    0.242058
New York     -1.701119
dtype: float64
>>> data.groupby(group_key).mean()
East    0.657288
West    0.041569
dtype: float64
>>> fill_mean=lambda g:g.fillna(g.mean())
>>> data.groupby(group_key).apply(fill_mean)
Oregon       -0.157550
Idaho         0.657288
Nevada        0.657288
Ohio          1.472126
Vermont       0.041569
Florida       1.583768
California    0.242058
New York     -1.701119
dtype: float64
>>> fill_values={'East':0.5,'West':-1}
>>> fill_func=lambda g:g.fillna(fill_values[g.name])
>>> data.groupby(group_key).apply(fill_func)
Oregon       -0.157550
Idaho         0.500000
Nevada        0.500000
Ohio          1.472126
Vermont      -1.000000
Florida       1.583768
California    0.242058
New York     -1.701119
dtype: float64










