>>> from pandas import Series,DataFrame
>>> import pandas as pd
>>> import numpy as np
>>> df=pd.DataFrame({'key1':['a','a','b','b','a'],
		     'key2':['one','two','one','two','one'],
		     'data1':np.random.randn(5),
		     'data2':np.random.randn(5)})
>>> df
  key1 key2     data1     data2
0    a  one  1.536150 -0.159347
1    a  two  1.145417  1.468526
2    b  one -0.649589 -0.960185
3    b  two  2.097288  0.153509
4    a  one -0.247084  1.503358
>>> grouped=df['data1'].groupby(df['key1'])
>>> grouped
<pandas.core.groupby.generic.SeriesGroupBy object at 0x0000000002FB8CF8>
>>> grouped.mean()
key1
a    0.811494
b    0.723849
Name: data1, dtype: float64
>>> means=df['data1'].groupby([df['key1'],df['key2']]).mean()
>>> means
key1  key2
a     one     0.644533
      two     1.145417
b     one    -0.649589
      two     2.097288
Name: data1, dtype: float64
>>> means.unstack()
key2       one       two
key1                    
a     0.644533  1.145417
b    -0.649589  2.097288
>>> states=np.array(['Ohio','California','California','Ohio','Ohio'])
>>> years=np.array([2005,2005,2006,2005,2006])
>>> df['data1'].groupby([states,years]).mean()
California  2005    1.145417
            2006   -0.649589
Ohio        2005    1.816719
            2006   -0.247084
Name: data1, dtype: float64
>>> df.groupby('key1').mean()
         data1     data2
key1                    
a     0.811494  0.937512
b     0.723849 -0.403338
>>> df.groupby(['key1','key2']).mean()
              data1     data2
key1 key2                    
a    one   0.644533  0.672005
     two   1.145417  1.468526
b    one  -0.649589 -0.960185
     two   2.097288  0.153509
>>> df.groupby(['key1','key2']).size()
key1  key2
a     one     2
      two     1
b     one     1
      two     1
dtype: int64
>>> for name,group in df.groupby('key1'):
	print(name)
	print(group)

a
  key1 key2     data1     data2
0    a  one  1.536150 -0.159347
1    a  two  1.145417  1.468526
4    a  one -0.247084  1.503358
b
  key1 key2     data1     data2
2    b  one -0.649589 -0.960185
3    b  two  2.097288  0.153509
>>> for (k1,k2),group in df.groupby(['key1','key2']):
	print((k1,k2))
	print(group)

	
('a', 'one')
  key1 key2     data1     data2
0    a  one  1.536150 -0.159347
4    a  one -0.247084  1.503358
('a', 'two')
  key1 key2     data1     data2
1    a  two  1.145417  1.468526
('b', 'one')
  key1 key2     data1     data2
2    b  one -0.649589 -0.960185
('b', 'two')
  key1 key2     data1     data2
3    b  two  2.097288  0.153509
>>> pieces=dict(list(df.groupby('key1')))
>>> pieces['b']
  key1 key2     data1     data2
2    b  one -0.649589 -0.960185
3    b  two  2.097288  0.153509
>>> #groupby默认在axis=0（行）上进行分组
>>> df.types
Traceback (most recent call last):
  File "<pyshell#32>", line 1, in <module>
    df.types
  File "D:\python\python3.6.6\lib\site-packages\pandas\core\generic.py", line 5067, in __getattr__
    return object.__getattribute__(self, name)
AttributeError: 'DataFrame' object has no attribute 'types'
>>> grouped=df.groupby(df.dtypes,axis=1)
>>> for dtype,group in grouped:
	print(dtype)
	print(group)

	
float64
      data1     data2
0  1.536150 -0.159347
1  1.145417  1.468526
2 -0.649589 -0.960185
3  2.097288  0.153509
4 -0.247084  1.503358
object
  key1 key2
0    a  one
1    a  two
2    b  one
3    b  two
4    a  one
>>> df.groupby('key1')['data1']
<pandas.core.groupby.generic.SeriesGroupBy object at 0x00000000055615C0>
>>> df.groupby('key1')[['data2']]
<pandas.core.groupby.generic.DataFrameGroupBy object at 0x0000000005561208>
>>> df['data1'].groupby(df['key1'])		   
<pandas.core.groupby.generic.SeriesGroupBy object at 0x0000000002FB8C50>
<pandas.core.groupby.generic.SeriesGroupBy object at 0x0000000002FB8C50>
>>> df[['data2']].groupby(df['key1'])
			   
<pandas.core.groupby.generic.DataFrameGroupBy object at 0x0000000005561198>
>>> df.groupby(['key1','key2'])[['data2']].mean()			   
              data2
key1 key2          
a    one   0.672005
     two   1.468526
b    one  -0.960185
     two   0.153509
>>> s_grouped=df.groupby(['key1','key2'])['data2']
>>> s_grouped
<pandas.core.groupby.generic.SeriesGroupBy object at 0x0000000005674780>
>>> s_grouped.mean()
			   
key1  key2
a     one     0.672005
      two     1.468526
b     one    -0.960185
      two     0.153509
Name: data2, dtype: float64
>>> people=pd.DataFrame(np.random.randn(5,5),columns=['a','b','c','d','e'],index=['Joe','Steve','Wes','Jim','Travis'])
			   
>>> people.iloc[2:3,[1,2]]=np.nan
			   
>>> people
			   
               a         b         c         d         e
Joe    -1.440956  0.483474 -0.310328 -1.137561 -1.312502
Steve  -0.587413 -0.590840 -0.161274 -0.498062  0.358051
Wes    -1.753277       NaN       NaN  0.048470  1.736482
Jim     0.746721  0.172708  0.798516  0.825998  1.177195
Travis -0.435557 -1.011992  0.107068 -0.240252  0.969837
>>> mapping={'a':'red','b':'red','c':'blue','d':'blue','e':'red','f':'orange'}
>>> by_column=people.groupby(mapping,axis=1)
			   
>>> by_column.sum()
			   
            blue       red
Joe    -1.447889 -2.269984
Steve  -0.659336 -0.820203
Wes     0.048470 -0.016795
Jim     1.624513  2.096625
Travis -0.133184 -0.477712
>>> map_series=pd.Series(mapping)
			   
>>> map_series
			   
a       red
b       red
c      blue
d      blue
e       red
f    orange
dtype: object
>>> people.groupby(map_series,axis=1).count()
			   
        blue  red
Joe        2    3
Steve      2    3
Wes        1    2
Jim        2    3
Travis     2    3
>>> people.groupby(len).sum()
			   
          a         b         c         d         e
3 -2.447512  0.656182  0.488188 -0.263094  1.601176
5 -0.587413 -0.590840 -0.161274 -0.498062  0.358051
6 -0.435557 -1.011992  0.107068 -0.240252  0.969837
>>> key_list=['one','one','one','two','two']
>>> people.groupby([len,key_list]).min()
		   
              a         b         c         d         e
3 one -1.753277  0.483474 -0.310328 -1.137561 -1.312502
  two  0.746721  0.172708  0.798516  0.825998  1.177195
5 one -0.587413 -0.590840 -0.161274 -0.498062  0.358051
6 two -0.435557 -1.011992  0.107068 -0.240252  0.969837
>>> columns=pd.MultiIndex.from_arrays([['US','US','US','JP','JP'],[1,3,5,1,3]],names=['cty','tenor'])
		   
>>> hier_df=pd.DataFrame(np.random.randn(4,5),columns=columns)
		   
>>> hier_df
		   
cty          US                            JP          
tenor         1         3         5         1         3
0     -0.403766  0.936847 -1.125547 -0.070928  1.382745
1     -0.140367 -0.675789 -2.260039  3.987206  0.365437
2      1.859973 -0.388325 -0.208550  1.520165  0.642543
3     -0.822489 -0.951763 -0.779612 -0.873974  1.118389
>>> hier_df.groupby(level='cty',axis=1).count()
		   
cty  JP  US
0     2   3
1     2   3
2     2   3
3     2   3
>>> df
		   
  key1 key2     data1     data2
0    a  one  1.536150 -0.159347
1    a  two  1.145417  1.468526
2    b  one -0.649589 -0.960185
3    b  two  2.097288  0.153509
4    a  one -0.247084  1.503358
>>> grouped=df.groupby('key1')
		   
>>> grouped['data1'].quantile(0.9)
		   
key1
a    1.458003
b    1.822600
Name: data1, dtype: float64
>>> def peak_to_peak(arr):
		   return arr.max()-arr.min()

		   
>>> grouped.agg(peak_to_peak)
		   
         data1     data2
key1                    
a     1.783234  1.662705
b     2.746877  1.113695
>>> grouped.describe()
		   
     data1                      ...     data2                    
     count      mean       std  ...       50%       75%       max
key1                            ...                              
a      3.0  0.811494  0.937341  ...  1.468526  1.485942  1.503358
b      2.0  0.723849  1.942335  ... -0.403338 -0.124914  0.153509

[2 rows x 16 columns]
>>> file='D:\python\pra\ex14.csv'
>>> tips=pd.read_csv(file)
>>> tips['tip_pct']=tips['tip']/tips['total_bill']
>>> tips[:6]
   total_bill   tip smoker  day    time  size   tip_pct
0       16.99  1.01     No  Sun  Dinner     2  0.059447
1       10.34  1.66     No  Sun  Dinner     3  0.160542
2       21.01  3.50     No  Sun  Dinner     3  0.166587
3       23.68  3.31     No  Sun  Dinner     2  0.139780
4       24.59  3.61     No  Sun  Dinner     4  0.146808
5       25.29  4.71     No  Sun  Dinner     4  0.186240
>>> grouped=tips.groupby(['day','smoker'])
>>> grouped_pct=grouped['tip_pct']
>>> grouped_pct.agg('mean')
day   smoker
Fri   No        0.151650
      Yes       0.174783
Sat   No        0.158048
      Yes       0.147906
Sun   No        0.160113
      Yes       0.187250
Thur  No        0.160298
      Yes       0.163863
Name: tip_pct, dtype: float64
>>> def peak_to_peak(arr):
	return arr.max()-arr.min()

>>> grouped_pct.agg(['mean','std',peak_to_peak])
                 mean       std  peak_to_peak
day  smoker                                  
Fri  No      0.151650  0.028123      0.067349
     Yes     0.174783  0.051293      0.159925
Sat  No      0.158048  0.039767      0.235193
     Yes     0.147906  0.061375      0.290095
Sun  No      0.160113  0.042347      0.193226
     Yes     0.187250  0.154134      0.644685
Thur No      0.160298  0.038774      0.193350
     Yes     0.163863  0.039389      0.151240
>>> grouped_pct.agg([('foo','mean',),('bar',np.std)])
                  foo       bar
day  smoker                    
Fri  No      0.151650  0.028123
     Yes     0.174783  0.051293
Sat  No      0.158048  0.039767
     Yes     0.147906  0.061375
Sun  No      0.160113  0.042347
     Yes     0.187250  0.154134
Thur No      0.160298  0.038774
     Yes     0.163863  0.039389
>>> functions=['count','mean','max']
>>> result=grouped['tip_pct','total_bill'].agg(functions)
>>> result
            tip_pct                     total_bill                  
              count      mean       max      count       mean    max
day  smoker                                                         
Fri  No           4  0.151650  0.187735          4  18.420000  22.75
     Yes         15  0.174783  0.263480         15  16.813333  40.17
Sat  No          45  0.158048  0.291990         45  19.661778  48.33
     Yes         42  0.147906  0.325733         42  21.276667  50.81
Sun  No          57  0.160113  0.252672         57  20.506667  48.17
     Yes         19  0.187250  0.710345         19  24.120000  45.35
Thur No          45  0.160298  0.266312         45  17.113111  41.19
     Yes         17  0.163863  0.241255         17  19.190588  43.11
>>> result['tip_pct']
             count      mean       max
day  smoker                           
Fri  No          4  0.151650  0.187735
     Yes        15  0.174783  0.263480
Sat  No         45  0.158048  0.291990
     Yes        42  0.147906  0.325733
Sun  No         57  0.160113  0.252672
     Yes        19  0.187250  0.710345
Thur No         45  0.160298  0.266312
     Yes        17  0.163863  0.241255
>>> ftuples=[('Durchschnitt','mean'),('Abweichung',np.var)]
>>> grouped['tip_pct','total_bill'].agg(ftuples)
                 tip_pct              total_bill            
            Durchschnitt Abweichung Durchschnitt  Abweichung
day  smoker                                                 
Fri  No         0.151650   0.000791    18.420000   25.596333
     Yes        0.174783   0.002631    16.813333   82.562438
Sat  No         0.158048   0.001581    19.661778   79.908965
     Yes        0.147906   0.003767    21.276667  101.387535
Sun  No         0.160113   0.001793    20.506667   66.099980
     Yes        0.187250   0.023757    24.120000  109.046044
Thur No         0.160298   0.001503    17.113111   59.625081
     Yes        0.163863   0.001551    19.190588   69.808518
>>> grouped.agg({'tip':np.max,'size':'sum'})
               tip  size
day  smoker             
Fri  No       3.50     9
     Yes      4.73    31
Sat  No       9.00   115
     Yes     10.00   104
Sun  No       6.00   167
     Yes      6.50    49
Thur No       6.70   112
     Yes      5.00    40
>>> tips.groupby(['day','smoker'],as_index=False).mean()
    day smoker  total_bill       tip      size   tip_pct
0   Fri     No   18.420000  2.812500  2.250000  0.151650
1   Fri    Yes   16.813333  2.714000  2.066667  0.174783
2   Sat     No   19.661778  3.102889  2.555556  0.158048
3   Sat    Yes   21.276667  2.875476  2.476190  0.147906
4   Sun     No   20.506667  3.167895  2.929825  0.160113
5   Sun    Yes   24.120000  3.516842  2.578947  0.187250
6  Thur     No   17.113111  2.673778  2.488889  0.160298
7  Thur    Yes   19.190588  3.030000  2.352941  0.163863
>>> def top(df,n=5,column='tip_pct'):
	return df.sort_values(by=column)[-n:]

>>> top(tips,n=6)
     total_bill   tip smoker  day    time  size   tip_pct
109       14.31  4.00    Yes  Sat  Dinner     2  0.279525
183       23.17  6.50    Yes  Sun  Dinner     4  0.280535
232       11.61  3.39     No  Sat  Dinner     2  0.291990
67         3.07  1.00    Yes  Sat  Dinner     1  0.325733
178        9.60  4.00    Yes  Sun  Dinner     2  0.416667
172        7.25  5.15    Yes  Sun  Dinner     2  0.710345
>>> tips.groupby('smoker').apply(top)
            total_bill   tip smoker   day    time  size   tip_pct
smoker                                                           
No     88        24.71  5.85     No  Thur   Lunch     2  0.236746
       185       20.69  5.00     No   Sun  Dinner     5  0.241663
       51        10.29  2.60     No   Sun  Dinner     2  0.252672
       149        7.51  2.00     No  Thur   Lunch     2  0.266312
       232       11.61  3.39     No   Sat  Dinner     2  0.291990
Yes    109       14.31  4.00    Yes   Sat  Dinner     2  0.279525
       183       23.17  6.50    Yes   Sun  Dinner     4  0.280535
       67         3.07  1.00    Yes   Sat  Dinner     1  0.325733
       178        9.60  4.00    Yes   Sun  Dinner     2  0.416667
       172        7.25  5.15    Yes   Sun  Dinner     2  0.710345
>>> tips.groupby(['smoker','day']).apply(top,n=1,column='total_bill')
                 total_bill    tip smoker   day    time  size   tip_pct
smoker day                                                             
No     Fri  94        22.75   3.25     No   Fri  Dinner     2  0.142857
       Sat  212       48.33   9.00     No   Sat  Dinner     4  0.186220
       Sun  156       48.17   5.00     No   Sun  Dinner     6  0.103799
       Thur 142       41.19   5.00     No  Thur   Lunch     5  0.121389
Yes    Fri  95        40.17   4.73    Yes   Fri  Dinner     4  0.117750
       Sat  170       50.81  10.00    Yes   Sat  Dinner     3  0.196812
       Sun  182       45.35   3.50    Yes   Sun  Dinner     3  0.077178
       Thur 197       43.11   5.00    Yes  Thur   Lunch     4  0.115982
>>> result=tips.groupby('smoker')['tip_pct'].describe()
>>> result
        count      mean       std  ...       50%       75%       max
smoker                             ...                              
No      151.0  0.159328  0.039910  ...  0.155625  0.185014  0.291990
Yes      93.0  0.163196  0.085119  ...  0.153846  0.195059  0.710345

[2 rows x 8 columns]
>>> result.unstack('smoker')
       smoker
count  No        151.000000
       Yes        93.000000
mean   No          0.159328
       Yes         0.163196
std    No          0.039910
       Yes         0.085119
min    No          0.056797
       Yes         0.035638
25%    No          0.136906
       Yes         0.106771
50%    No          0.155625
       Yes         0.153846
75%    No          0.185014
       Yes         0.195059
max    No          0.291990
       Yes         0.710345
dtype: float64
>>> f=lambda x:x.describe()
>>> grouped.apply(f)
                   total_bill        tip       size    tip_pct
day  smoker                                                   
Fri  No     count    4.000000   4.000000   4.000000   4.000000
            mean    18.420000   2.812500   2.250000   0.151650
            std      5.059282   0.898494   0.500000   0.028123
            min     12.460000   1.500000   2.000000   0.120385
            25%     15.100000   2.625000   2.000000   0.137239
            50%     19.235000   3.125000   2.000000   0.149241
            75%     22.555000   3.312500   2.250000   0.163652
            max     22.750000   3.500000   3.000000   0.187735
     Yes    count   15.000000  15.000000  15.000000  15.000000
            mean    16.813333   2.714000   2.066667   0.174783
            std      9.086388   1.077668   0.593617   0.051293
            min      5.750000   1.000000   1.000000   0.103555
            25%     11.690000   1.960000   2.000000   0.133739
            50%     13.420000   2.500000   2.000000   0.173913
            75%     18.665000   3.240000   2.000000   0.209240
            max     40.170000   4.730000   4.000000   0.263480
Sat  No     count   45.000000  45.000000  45.000000  45.000000
            mean    19.661778   3.102889   2.555556   0.158048
            std      8.939181   1.642088   0.784960   0.039767
            min      7.250000   1.000000   1.000000   0.056797
            25%     14.730000   2.010000   2.000000   0.136240
            50%     17.820000   2.750000   2.000000   0.150152
            75%     20.650000   3.390000   3.000000   0.183915
            max     48.330000   9.000000   4.000000   0.291990
     Yes    count   42.000000  42.000000  42.000000  42.000000
            mean    21.276667   2.875476   2.476190   0.147906
            std     10.069138   1.630580   0.862161   0.061375
            min      3.070000   1.000000   1.000000   0.035638
            25%     13.405000   2.000000   2.000000   0.091797
            50%     20.390000   2.690000   2.000000   0.153624
...                       ...        ...        ...        ...
Sun  No     std      8.130189   1.224785   1.032674   0.042347
            min      8.770000   1.010000   2.000000   0.059447
            25%     14.780000   2.000000   2.000000   0.139780
            50%     18.430000   3.020000   3.000000   0.161665
            75%     25.000000   3.920000   4.000000   0.185185
            max     48.170000   6.000000   6.000000   0.252672
     Yes    count   19.000000  19.000000  19.000000  19.000000
            mean    24.120000   3.516842   2.578947   0.187250
            std     10.442511   1.261151   0.901591   0.154134
            min      7.250000   1.500000   2.000000   0.065660
            25%     17.165000   3.000000   2.000000   0.097723
            50%     23.100000   3.500000   2.000000   0.138122
            75%     32.375000   4.000000   3.000000   0.215325
            max     45.350000   6.500000   5.000000   0.710345
Thur No     count   45.000000  45.000000  45.000000  45.000000
            mean    17.113111   2.673778   2.488889   0.160298
            std      7.721728   1.282964   1.179796   0.038774
            min      7.510000   1.250000   1.000000   0.072961
            25%     11.690000   1.800000   2.000000   0.137741
            50%     15.950000   2.180000   2.000000   0.153492
            75%     20.270000   3.000000   2.000000   0.184843
            max     41.190000   6.700000   6.000000   0.266312
     Yes    count   17.000000  17.000000  17.000000  17.000000
            mean    19.190588   3.030000   2.352941   0.163863
            std      8.355149   1.113491   0.701888   0.039389
            min     10.340000   2.000000   2.000000   0.090014
            25%     13.510000   2.000000   2.000000   0.148038
            50%     16.470000   2.560000   2.000000   0.153846
            75%     19.810000   4.000000   2.000000   0.194837
            max     43.110000   5.000000   4.000000   0.241255

[64 rows x 4 columns]
>>> tips.groupby('smoker',group_keys=False).apply(top)
     total_bill   tip smoker   day    time  size   tip_pct
88        24.71  5.85     No  Thur   Lunch     2  0.236746
185       20.69  5.00     No   Sun  Dinner     5  0.241663
51        10.29  2.60     No   Sun  Dinner     2  0.252672
149        7.51  2.00     No  Thur   Lunch     2  0.266312
232       11.61  3.39     No   Sat  Dinner     2  0.291990
109       14.31  4.00    Yes   Sat  Dinner     2  0.279525
183       23.17  6.50    Yes   Sun  Dinner     4  0.280535
67         3.07  1.00    Yes   Sat  Dinner     1  0.325733
178        9.60  4.00    Yes   Sun  Dinner     2  0.416667
172        7.25  5.15    Yes   Sun  Dinner     2  0.710345
>>> frame=pd.DataFrame({'data1':np.random.randn(1000),
			'data2':np.random.randn(1000)})
>>> quartiles=pd.cut(frame.data1,4)
>>> quartiles[:10]
0    (-1.853, -0.319]
1     (-0.319, 1.215]
2     (-0.319, 1.215]
3      (1.215, 2.749]
4    (-1.853, -0.319]
5     (-0.319, 1.215]
6    (-1.853, -0.319]
7     (-0.319, 1.215]
8    (-1.853, -0.319]
9     (-0.319, 1.215]
Name: data1, dtype: category
Categories (4, interval[float64]): [(-3.393, -1.853] < (-1.853, -0.319] < (-0.319, 1.215] <
                                    (1.215, 2.749]]
>>> def get_stats(group):
	return{'min':group.min(),'max':group.max(),'count':group.count(),'mean':		group.mean()}

>>> grouped=frame.data2.groupby(quartiles)
>>> grouped.apply(get_stats).unstack()
                  count       max      mean       min
data1                                                
(-3.393, -1.853]   37.0  2.188095  0.147096 -1.340250
(-1.853, -0.319]  334.0  3.080357 -0.061646 -2.798341
(-0.319, 1.215]   513.0  3.565056  0.015422 -3.195236
(1.215, 2.749]    116.0  2.272575 -0.020101 -3.002138
>>> grouping=pd.qcut(frame.data1,10,labels=False)
>>> grouped=frame.data2.groupby(grouping)
>>> grouped.apply(get_stats).unstack()
       count       max      mean       min
data1                                     
0      100.0  2.457694  0.171359 -2.012314
1      100.0  2.814799 -0.160352 -2.027281
2      100.0  3.080357 -0.064555 -2.798341
3      100.0  2.169957 -0.127208 -2.394483
4      100.0  2.668277 -0.075201 -3.195236
5      100.0  2.166386  0.167581 -2.258811
6      100.0  3.565056  0.164672 -1.957359
7      100.0  2.057231 -0.086912 -2.685742
8      100.0  2.777569 -0.039647 -1.996672
9      100.0  2.272575 -0.045410 -3.002138
>>> s=pd.Series(np.random.randn(6))
>>> s[::2]=np.nan
>>> s
0         NaN
1    0.786685
2         NaN
3   -0.337087
4         NaN
5   -1.622295
dtype: float64
>>> s.fillna(s.mean())
0   -0.390899
1    0.786685
2   -0.390899
3   -0.337087
4   -0.390899
5   -1.622295
dtype: float64
>>> states={'Ohio','New York','Vermont','Florida','Oregon','Nevada','California'	,'Idaho'}
>>> group_key=['East']*4+['West']*4
>>> data=pd.Series(np.random.randn(8),index=states)
>>> data
Oregon       -0.157550
Idaho        -0.459462
Nevada        0.747336
Ohio          1.472126
Vermont      -0.629245
Florida       1.583768
California    0.242058
New York     -1.701119
dtype: float64
>>> data[['Vermont','Nevada','Idaho']]=np.nan
>>> data
Oregon       -0.157550
Idaho              NaN
Nevada             NaN
Ohio          1.472126
Vermont            NaN
Florida       1.583768
California    0.242058
New York     -1.701119
dtype: float64
>>> data.groupby(group_key).mean()
East    0.657288
West    0.041569
dtype: float64
>>> fill_mean=lambda g:g.fillna(g.mean())
>>> data.groupby(group_key).apply(fill_mean)
Oregon       -0.157550
Idaho         0.657288
Nevada        0.657288
Ohio          1.472126
Vermont       0.041569
Florida       1.583768
California    0.242058
New York     -1.701119
dtype: float64
>>> fill_values={'East':0.5,'West':-1}
>>> fill_func=lambda g:g.fillna(fill_values[g.name])
>>> data.groupby(group_key).apply(fill_func)
Oregon       -0.157550
Idaho         0.500000
Nevada        0.500000
Ohio          1.472126
Vermont      -1.000000
Florida       1.583768
California    0.242058
New York     -1.701119
dtype: float64
>>> suits=['H','S','C','D']
>>> card_val=(list(range(1,11))+[10]*3)*4
>>> base_names=['A']+list(range(2,11))+['J','K','Q']
>>> cards=[]
>>> for suit in ['H','S','C','D']:
	cards.extend(str(num)+suit for num in base_names)

	
>>> deck=pd.Series(card_val,index=cards)
>>> deck[:13]
AH      1
2H      2
3H      3
4H      4
5H      5
6H      6
7H      7
8H      8
9H      9
10H    10
JH     10
KH     10
QH     10
dtype: int64
>>> def draw(deck,n=5):
	return deck.sample(n)

>>> draw(deck)
8S     8
8D     8
KD    10
AH     1
KC    10
dtype: int64
>>> get_suit=lambda card:card[-1]
>>> deck.groupby(get_suit).apply(draw,n=2)
C  2C      2
   3C      3
D  8D      8
   10D    10
H  2H      2
   10H    10
S  10S    10
   7S      7
dtype: int64
>>> deck.groupby(get_suit,group_keys=False).apply(draw,n=2)
AC     1
4C     4
9D     9
2D     2
QH    10
3H     3
4S     4
9S     9
dtype: int64
>>> df=pd.DataFrame({'category':['a','a','a','a','b','b','b','b'],'data':np.random.randn(8),'weights':np.random.randn(8)})
>>> df
  category      data   weights
0        a  0.345812  1.203131
1        a -0.148815  0.288905
2        a  0.960088 -1.237029
3        a -2.495115 -0.179166
4        b -0.615523  0.754069
5        b  1.623408 -1.005177
6        b -0.900426 -0.315588
7        b  0.772014  1.217957
>>> grouped=df.groupby('category')
>>> get_wavg=lambda g:np.average(g['data'],weights=g['weights'])
>>> grouped.apply(get_wavg)
category
a   -4.846389
b   -1.338197
dtype: float64
>>> file='D:\python\pra\ex15.csv'
>>> close_px=pd.read_csv(file,parse_dates=True,index_col=0)
>>> close_px.info()
<class 'pandas.core.frame.DataFrame'>
DatetimeIndex: 2214 entries, 2003-01-02 to 2011-10-14
Data columns (total 4 columns):
AAPL    2214 non-null float64
MSFT    2214 non-null float64
XOM     2214 non-null float64
SPX     2214 non-null float64
dtypes: float64(4)
memory usage: 86.5 KB
>>> close_px[-4:]
              AAPL   MSFT    XOM      SPX
2011-10-11  400.29  27.00  76.27  1195.54
2011-10-12  402.19  26.96  77.16  1207.25
2011-10-13  408.43  27.18  76.37  1203.66
2011-10-14  422.00  27.27  78.11  1224.58
>>> spx_corr=lambda x:x.corrwith(x['SPX'])
>>> rets=close_px.pct_change().dropna()
>>> get_year=lambda x:x.year
>>> by_year=rets.groupby(get_year)
>>> by_year.apply(spx_corr)
          AAPL      MSFT       XOM  SPX
2003  0.541124  0.745174  0.661265  1.0
2004  0.374283  0.588531  0.557742  1.0
2005  0.467540  0.562374  0.631010  1.0
2006  0.428267  0.406126  0.518514  1.0
2007  0.508118  0.658770  0.786264  1.0
2008  0.681434  0.804626  0.828303  1.0
2009  0.707103  0.654902  0.797921  1.0
2010  0.710105  0.730118  0.839057  1.0
2011  0.691931  0.800996  0.859975  1.0
>>> by_year.apply(lambda g:g['AAPL'].corr(g['MSFT']))
2003    0.480868
2004    0.259024
2005    0.300093
2006    0.161735
2007    0.417738
2008    0.611901
2009    0.432738
2010    0.571946
2011    0.581987
dtype: float64
>>> import statsmodels.api as sm
Traceback (most recent call last):
  File "<pyshell#34>", line 1, in <module>
    import statsmodels.api as sm
ModuleNotFoundError: No module named 'statsmodels'
>>> def regress(data,yvar,xvars):
	Y=data[yvar]
	X=data[xvars]
	X['intercept']=1.
	result=sm.OLS(Y,X).fit()
	return result.params

>>> by_year.apply(regress,'AAPL',['SPX'])
Traceback (most recent call last):
  File "D:\python\python3.6.6\lib\site-packages\pandas\core\groupby\groupby.py", line 689, in apply
    result = self._python_apply_general(f)
  File "D:\python\python3.6.6\lib\site-packages\pandas\core\groupby\groupby.py", line 707, in _python_apply_general
    self.axis)
  File "D:\python\python3.6.6\lib\site-packages\pandas\core\groupby\ops.py", line 190, in apply
    res = f(group)
  File "D:\python\python3.6.6\lib\site-packages\pandas\core\groupby\groupby.py", line 679, in f
    return func(g, *args, **kwargs)
  File "<pyshell#41>", line 5, in regress
    result=sm.OLS(Y,X).fit()
NameError: name 'sm' is not defined

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "<pyshell#42>", line 1, in <module>
    by_year.apply(regress,'AAPL',['SPX'])
  File "D:\python\python3.6.6\lib\site-packages\pandas\core\groupby\groupby.py", line 701, in apply
    return self._python_apply_general(f)
  File "D:\python\python3.6.6\lib\site-packages\pandas\core\groupby\groupby.py", line 707, in _python_apply_general
    self.axis)
  File "D:\python\python3.6.6\lib\site-packages\pandas\core\groupby\ops.py", line 190, in apply
    res = f(group)
  File "D:\python\python3.6.6\lib\site-packages\pandas\core\groupby\groupby.py", line 679, in f
    return func(g, *args, **kwargs)
  File "<pyshell#41>", line 5, in regress
    result=sm.OLS(Y,X).fit()
NameError: name 'sm' is not defined
>>> file='D:python\pra\ex15.csv'
>>> tips=pd.read_csv(file)
Traceback (most recent call last):
  File "<pyshell#44>", line 1, in <module>
    tips=pd.read_csv(file)
  File "D:\python\python3.6.6\lib\site-packages\pandas\io\parsers.py", line 702, in parser_f
    return _read(filepath_or_buffer, kwds)
  File "D:\python\python3.6.6\lib\site-packages\pandas\io\parsers.py", line 429, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "D:\python\python3.6.6\lib\site-packages\pandas\io\parsers.py", line 895, in __init__
    self._make_engine(self.engine)
  File "D:\python\python3.6.6\lib\site-packages\pandas\io\parsers.py", line 1122, in _make_engine
    self._engine = CParserWrapper(self.f, **self.options)
  File "D:\python\python3.6.6\lib\site-packages\pandas\io\parsers.py", line 1853, in __init__
    self._reader = parsers.TextReader(src, **kwds)
  File "pandas\_libs\parsers.pyx", line 387, in pandas._libs.parsers.TextReader.__cinit__
  File "pandas\_libs\parsers.pyx", line 705, in pandas._libs.parsers.TextReader._setup_parser_source
FileNotFoundError: [Errno 2] File b'D:python\\pra\\ex15.csv' does not exist: b'D:python\\pra\\ex15.csv'
>>> file='D:python\pra\ex14.csv'
>>> tips=pd.read_csv(file)
Traceback (most recent call last):
  File "<pyshell#46>", line 1, in <module>
    tips=pd.read_csv(file)
  File "D:\python\python3.6.6\lib\site-packages\pandas\io\parsers.py", line 702, in parser_f
    return _read(filepath_or_buffer, kwds)
  File "D:\python\python3.6.6\lib\site-packages\pandas\io\parsers.py", line 429, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
  File "D:\python\python3.6.6\lib\site-packages\pandas\io\parsers.py", line 895, in __init__
    self._make_engine(self.engine)
  File "D:\python\python3.6.6\lib\site-packages\pandas\io\parsers.py", line 1122, in _make_engine
    self._engine = CParserWrapper(self.f, **self.options)
  File "D:\python\python3.6.6\lib\site-packages\pandas\io\parsers.py", line 1853, in __init__
    self._reader = parsers.TextReader(src, **kwds)
  File "pandas\_libs\parsers.pyx", line 387, in pandas._libs.parsers.TextReader.__cinit__
  File "pandas\_libs\parsers.pyx", line 705, in pandas._libs.parsers.TextReader._setup_parser_source
FileNotFoundError: [Errno 2] File b'D:python\\pra\\ex14.csv' does not exist: b'D:python\\pra\\ex14.csv'
>>> file='D:\python\pra\ex14.csv'
>>> tips=pd.read_csv(file)
>>> tips['tip_pct']=tips['tip']/tips['total_bill']
>>> tips[:6]
   total_bill   tip smoker  day    time  size   tip_pct
0       16.99  1.01     No  Sun  Dinner     2  0.059447
1       10.34  1.66     No  Sun  Dinner     3  0.160542
2       21.01  3.50     No  Sun  Dinner     3  0.166587
3       23.68  3.31     No  Sun  Dinner     2  0.139780
4       24.59  3.61     No  Sun  Dinner     4  0.146808
5       25.29  4.71     No  Sun  Dinner     4  0.186240
>>> tips.pivot_table(index=['day','smoker'])
                 size       tip   tip_pct  total_bill
day  smoker                                          
Fri  No      2.250000  2.812500  0.151650   18.420000
     Yes     2.066667  2.714000  0.174783   16.813333
Sat  No      2.555556  3.102889  0.158048   19.661778
     Yes     2.476190  2.875476  0.147906   21.276667
Sun  No      2.929825  3.167895  0.160113   20.506667
     Yes     2.578947  3.516842  0.187250   24.120000
Thur No      2.488889  2.673778  0.160298   17.113111
     Yes     2.352941  3.030000  0.163863   19.190588
>>> #假设想要根据day和smoke计算分组平均数（pivot_table）的默认聚合类型，并将day和smoker放到行上
>>> tips.pivot_table(['tip_pct','size'],index=['time','day'],columns='smoker',margins=True)
                 size                       tip_pct                    
smoker             No       Yes       All        No       Yes       All
time   day                                                             
Dinner Fri   2.000000  2.222222  2.166667  0.139622  0.165347  0.158916
       Sat   2.555556  2.476190  2.517241  0.158048  0.147906  0.153152
       Sun   2.929825  2.578947  2.842105  0.160113  0.187250  0.166897
       Thur  2.000000       NaN  2.000000  0.159744       NaN  0.159744
Lunch  Fri   3.000000  1.833333  2.000000  0.187735  0.188937  0.188765
       Thur  2.500000  2.352941  2.459016  0.160311  0.163863  0.161301
All          2.668874  2.408602  2.569672  0.159328  0.163196  0.160803
>>> tips.pivot_table('tip_pct',index=['time','smoker'],columns='day',aggfunc=len,margins=True)
day             Fri   Sat   Sun  Thur    All
time   smoker                               
Dinner No       3.0  45.0  57.0   1.0  106.0
       Yes      9.0  42.0  19.0   NaN   70.0
Lunch  No       1.0   NaN   NaN  44.0   45.0
       Yes      6.0   NaN   NaN  17.0   23.0
All            19.0  87.0  76.0  62.0  244.0
>>> tips.pivot_table('tip_pct',index=['time','size','smoker'],columns='day',aggfunc='mean',fill_value=0)
day                      Fri       Sat       Sun      Thur
time   size smoker                                        
Dinner 1    No      0.000000  0.137931  0.000000  0.000000
            Yes     0.000000  0.325733  0.000000  0.000000
       2    No      0.139622  0.162705  0.168859  0.159744
            Yes     0.171297  0.148668  0.207893  0.000000
       3    No      0.000000  0.154661  0.152663  0.000000
            Yes     0.000000  0.144995  0.152660  0.000000
       4    No      0.000000  0.150096  0.148143  0.000000
            Yes     0.117750  0.124515  0.193370  0.000000
       5    No      0.000000  0.000000  0.206928  0.000000
            Yes     0.000000  0.106572  0.065660  0.000000
       6    No      0.000000  0.000000  0.103799  0.000000
Lunch  1    No      0.000000  0.000000  0.000000  0.181728
            Yes     0.223776  0.000000  0.000000  0.000000
       2    No      0.000000  0.000000  0.000000  0.166005
            Yes     0.181969  0.000000  0.000000  0.158843
       3    No      0.187735  0.000000  0.000000  0.084246
            Yes     0.000000  0.000000  0.000000  0.204952
       4    No      0.000000  0.000000  0.000000  0.138919
            Yes     0.000000  0.000000  0.000000  0.155410
       5    No      0.000000  0.000000  0.000000  0.121389
       6    No      0.000000  0.000000  0.000000  0.173706
>>> data
Traceback (most recent call last):
  File "<pyshell#56>", line 1, in <module>
    data
NameError: name 'data' is not defined
>>> pd.crosstab([tips.time,tips.day],tips.smoker,margins=True)
smoker        No  Yes  All
time   day                
Dinner Fri     3    9   12
       Sat    45   42   87
       Sun    57   19   76
       Thur    1    0    1
Lunch  Fri     1    6    7
       Thur   44   17   61
All          151   93  244
>>> 










